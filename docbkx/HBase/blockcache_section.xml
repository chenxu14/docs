<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:ns5="http://www.w3.org/2000/svg"
	xmlns:ns4="http://www.w3.org/1998/Math/MathML"
	xmlns:ns3="http://www.w3.org/1999/xhtml"
	xmlns:db="http://docbook.org/ns/docbook">
	<title>BlockCache功能</title>
	<para>BlockCache主要用于读缓存功能，以此来加快数据块的访问效率，目前HBase提供了两种该缓存功能的实现类，分别是LruBlockCache和BucketCache(国人研发)，其中LruBlockCache是较早的实现版本，采用LRU算法淘汰缓存中久不使用的数据，该缓存的主要问题在于每次执行CMS垃圾回收时，有可能会产生大量的内存碎片，从而降低了整个堆内存的可用率，为此BucketCache应运而生。</para>
	<section>
		<title>LruBlockCache</title>
		<para>LruBlockCache是最早的缓存功能实现类，其内部主要采用HashMap来存储每一个要缓存的数据块。在LruBlockCache缓存中，缓存数据是分3个区域来存储的，不同区域存储着不同性质的block数据，这些区域包括：</para>
		<itemizedlist make='bullet'>
			<listitem>
				<para>single-access区域</para>
				<para>该区域中所存储的block只被访问过1次，区域空间上限为整个缓存的1/4(通过hbase.lru.blockcache.single.percentage参数来指定)；</para>
			</listitem>
			<listitem>
				<para>multi-access区域</para>
				<para>如果block已经不止一次被访问，将该block存储到该区域，为其分配的空间大小为整个缓存空间的1/2(通过hbase.lru.blockcache.multi.percentage参数来指定)；</para>
			</listitem>
			<listitem>
				<para>in-memory区域</para>
				<para>如果创建columnFamily时指定了IN_MEMORY标识，则列簇所对应的block数据存储在该区域,为其分配的空间大小为整个缓存的1/4(通过hbase.lru.blockcache.memory.percentage参数来指定)。</para>
			</listitem>
		</itemizedlist>
		<para>每一个存储区域都采用LRU算法进行实现，存储最近最新访问的数据，需要注意的是in-memory区域，如果含有IN_MEMORY标识的列簇较多，而且数据量比较大，则需要提高该区域所占缓存空间的百分比，来防止META表格数据被驱逐的情况。</para>
		<para>当LruBlockCache的缓存空间使用率达到一定比例时(通过hbase.lru.blockcache.acceptable.factor配置参数指定，默认为0.99)，需要对缓存中相对使用不频繁的数据进行清理，来防止缓存空间的溢出。为此LruBlockCache在构建时会开启一个EvictionThread后台线程来定期检测要清理的数据，检测频率为10秒。</para>
		<para>线程在每次迭代中会首先判断缓存的使用空间是否已经低于hbase.lru.blockcache.min.factor参数所设置的百分比(默认为0.95)，如果低于该阀值，则没有必要执行清理操作，否则计算出需要清理的缓存空间：</para>
		<blockquote><para>要清理的空间 = 缓存使用量 - 缓存空间上限 * hbase.lru.blockcache.min.factor</para></blockquote>
		<para>执行清理操作前，LruBlockCache会针对每个存储区域创建一个BlockBucket实体，通过它来统计每个区域访问频率相对不频繁的数据(这部分数据大小不会超过缓存要清理的空间)，然后对其进行清理操作。但是由于LruBlockCache包含3个存储区域，将每个区域的统计数据相加，其值有可能已经超过了需要释放空间的总大小(是其3倍)，因此在执行清理操作前，还需对每个区域进行优先级比较，来决定哪些数据应该被优先清理。具体的比较方法是：哪个区域的剩余空间越小(如果某个区域的存储空间溢出则其剩余空间为负)，其优先处理的级别越高。</para>
		<para>在处理优先级决定之后采用如下公式来顺序计算每个区域需要释放的空间大小：</para>
		<blockquote><para>Math.min(区域溢出空间, (要清理的空间) / remainingBuckets)</para></blockquote>
		<para>其中区域溢出空间是相对于每个区域的最小阈值来计算的，而remainingBuckets初始值为3，每处理完一个区域后将其值减1，并重新计算"要清理的空间"大小。如果某个区域的溢出空间为0(缓存使用量没有超过其区间的最小阈值)，则不对其进行驱逐处理。</para>
		<section>
			<title>缓存配置</title>
			<para>有关BucketCache的配置参数如下：</para>
			<orderedlist>
				<listitem>
					<para>hfile.block.cache.size</para>
					<para>用于LRUCache的内存占用堆内存的百分比(0~1之，如果为0表示禁用缓存功能)；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.blockcache.acceptable.factor</para>
					<para>block使用空间达到该阀值时(默认为0.99)，执行evicting；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.blockcache.min.factor</para>
					<para>缓存的使用空间小于该百分比时(默认为0.95)不执行evicting；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.blockcache.single.percentage</para>
					<para>single-access空间百分比(默认为25%)，block初始访问时，存放到该区域；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.blockcache.multi.percentage</para>
					<para>multi-access空间百分比(默认为50%)，block连续访问时，存放该区域；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.blockcache.memory.percentage</para>
					<para>in-memory空间百分比(默认为25%)；</para>
				</listitem>
				<listitem>
					<para>hbase.lru.rs.inmemoryforcemode</para>
					<para>不对inmemory区域进行驱逐操作，使其数据一直常驻内存，直至LRUCache装载不了为止。</para>
				</listitem>
			</orderedlist>
		</section>
	</section>
	<section>
		<title>BucketCache</title>
		<para>BucketCache的产生主要用于解决CMS过程中内存碎片的问题，不同于LruBlockCache采用HashMap作为block的存储媒介，在BucketCache中缓存数据是通过ByteBuffer(存储媒介为内存)或file(存储媒介为高速磁盘，比如SSD)来存储的。在使用内存作为存储媒介时，考虑到如果采用单个ByteBuffer来存储所有的数据，数据的寻址时间和读写效率可能会有影响，因此，BucketCache的做法是采用一组ByteBuffer进行存储，每个ByteBuffer存储着4M的缓存数据，在根据BucketCache的大小(hbase.bucketcache.size参数指定)来决定需要申请的ByteBuffer个数。这些ByteBuffer数组在物理存储上可能并不是连续的地址空间，但是在逻辑上我们可以认为它们是连续的，从而形成一个更为庞大的ByteBuffer实体，存储着全部的缓存数据。</para>
		<para>在物理层面缓存数据是通过ByteBuffe或file来存储的，而在逻辑层面存储单元是通过Bucket来封装的。BucketCache将所有的缓存空间划分成了多个Bucket，每个Bucket负责封装2M的block数据。同时这些Bucket又是分组管理的，不同的Bucket分组存储着不同size的block数据，假设hbase.bucketcache.bucket.sizes的属性值为(64kb,96kb,512kb)，则BucketCache在初始化时会创建3个Bucket分组来分别存储64kb大小的block、96kb大小的block和512kb大小的block。而每个Bucket分组所包含的Bucket数量是通过如下方式来计算出来的：</para>
		<blockquote>
			<itemizedlist make='bullet'>
				<listitem><para>首先为每个Bucket分组都分配一个Bucket；</para></listitem>
				<listitem><para>将剩余的Bucket全部分配到具有最大size标签的Bucket分组里(即这里存储512kb的Bucket分组)。</para></listitem>
			</itemizedlist>
		</blockquote>
		<para>那么这里可能会存在疑问，假如64kb的Bucket分组和96kb的Bucket分组使用空间溢出了该怎么办？没关系，他们可以抢占其他分组中的Bucket进行存储，即将512kb分组中的Bucket移动到自己的分组中，但同时是也存在一个前提条件：即要抢占的Bucket目前还没有存放任何数据，目的是为了保证每一个Bucket只能存储一种size的block。</para>
		<section>
			<title>读写逻辑</title>
			<para>在BucketCache中封装了以下数据结构用于存储相关的数据信息：</para>
			<itemizedlist make='bullet'>
				<listitem>
					<para>ramCache，存储结构为Map&lt;BlockCacheKey, RAMQueueEntry></para>
					<para>在BucketCache中要缓存的数据是通过RAMQueueEntry实体来封装的，每个block数据在写入缓存之前会暂存于该ramCache集合中(相当于缓存数据的缓冲区)，待数据写入缓存区后，在将其从ramCache中删除。</para>
				</listitem>
				<listitem>
					<para>backingMap，存储结构为ConcurrentHashMap&lt;BlockCacheKey, BucketEntry></para>
					<para>该集合主要用于存储缓存数据的元数据信息(存储位置、大小长度、逻辑区域等)，这样当数据成功缓存后，便可通过这些元数据信息将已缓存的数据定位到。</para>
				</listitem>
				<listitem>
					<para>writerQueues，存储结构为ArrayList&lt;BlockingQueue&lt;RAMQueueEntry>></para>
					<para>数据的缓存过程是基于生产者-消费者模式来设计的，该数据结构主要用于存储消费队列，针对每一个消费队列，BucketCache都会开启相应的WriterThread线程来消费其中的内容(消费过程主要是将数据写入缓存区)。每个消费队列的初始容量是通过hbase.bucketcache.writer.queuelength参数来指定的(默认为64)，而消费队列的个数是通过hbase.bucketcache.writer.threads参数来决定的。</para>
				</listitem>
			</itemizedlist>
			<orderedlist>
				<listitem>
					<para>缓存逻辑</para>
					<para>缓存逻辑是通过cacheBlock方法来实现的，方法执行时首先构造出RAMQueueEntry实体用于封装将要缓存的block数据，然后将该数据实体加入到ramCache缓冲区和writerQueue消费队列，供相应的WriterThread线程进行消费处理。</para>
					<para>WriterThread线程在启动后会循环遍历与它对应的writerQueue队列，当有新RAMQueueEntry实体出现时，会执行其writeToCache方法，将block数据写入缓存，具体的写入逻辑如下：</para>
					<itemizedlist make='bullet'>
						<listitem>首先判断出将要缓存的block大小，然后遍历所有的Bucket分组，找出size标签与该block大小最为接近的分组(Bucket分组是通过BucketSizeInfo对象来封装的)；</listitem>
						<listitem>分组信息确定后，执行其allocateBlock方法来查找含有剩余使用空间的Bucket，如果该Bucket分组的使用空间已满，开始执行Bucket抢占，将其他分组中尚未使用的Bucket移动到自己的分组中；</listitem>
						<listitem>
							<para>确定了Bucket信息之后，开始执行其allocate方法来为要缓存的数据块分配存储空间；</para>
							<para>Bucket是基于可覆写模式来设计，其内部封装了以下数据信息：</para>
							<para>(1)baseOffset：Bucket存储区域的起始位置在缓存中的偏移量信息，通过它可定位缓存数据的物理存储位置；</para>
							<para>(2)itemAllocationSize：存储哪种size的block信息；</para>
							<para>(3)freeCount：还能存储的block个数；</para>
							<para>(4)freeList[]：记录该bucket中哪些block可执行覆写操作(即其所占用的空间在逻辑上已被清理)；</para>
							<para>allocate方法在执行时，会从freeList中选择一个空闲的block，根据其索引位置和itemAllocationSize大小来计算其在Bucket中的偏移量信息(offset-in-bucket)，计算出offset-in-bucket后，在根据baseOffset信息，便可计算出该block在整个缓存空间上的物理位置，将要缓存的数据从该位置写入即可(通过IOEngine的write方法)，由于该Bucket只存储itemAllocationSize大小的block数据，因此新写入的数据长度会和以前旧数据的长度相同，从而完美覆盖了以前的旧数据，防止了空间碎片的产生。</para>
						</listitem>
						<listitem>缓存数据写入成功后，构造BucketEntry实体来封装该block的元数据信息(存储偏移量、数据长度等)，并将其加入backingMap集合，便于通过它来获取已缓存的数据；</listitem>
						<listitem>最后将已缓存的RAMQueueEntry实体从ramCache缓冲区中移除，至此缓存操作成功结束。</listitem>
					</itemizedlist>
				</listitem>
				<listitem>
					<para>读取逻辑</para>
					<itemizedlist make='bullet'>
						<listitem>首先从ramCache缓冲区中进行读取，因为block在写入缓存之前都会暂存与该缓冲区中，如果缓冲区中没有找到想要读取的block数据，说明该block有可能已经被缓存(缓存成功后会从缓冲区中移除相应数据)，执行下一步查找；</listitem>
						<listitem>遍历backingMap集合，查找block对应的元数据信息，在由元数据(存储偏移量、大小长度)来确定block的存储位置，并通过IOEngine的read方法将其数据读取出来；</listitem>
						<listitem>如果backingMap集合中也没有找到指定block的元数据信息，说明该block目前还没有被缓存，需要从HFile中进行读取。</listitem>
					</itemizedlist>
				</listitem>
				<listitem>
					<para>驱逐逻辑</para>
					<para>同LruBlockCache缓存类似，BucketCache所缓存的数据在逻辑上也是分3个区域来存储的，其中single-access区占25%，multi-access区占50%，in-memory区占25%(目前为硬编码的方式，没有相关参数进行设置)，当缓存空间的使用率达到95%时开始采用LRU算法对久不使用的数据进行驱逐处理，来防止缓存空间的使用溢出。每个区域需要释放的空间大小及处理优先级同LruBlockCache的计算方法相似，只不过在执行block清理时不在是简单的将其从HashMap中移除，而需进行如下处理：</para>
					<itemizedlist make='bullet'>
						<listitem>首先，将要驱逐的数据块从ramCache集合和backingMap集合中移除；</listitem>
						<listitem>
							<para>然后，遍历backingMap集合，从中获取要驱逐的block元数据信息(存储偏移量、长度)，在通过BucketAllocator的freeBlock方法将其使用空间进行逻辑释放(标记为可覆写)，具体逻辑如下：</para>
							<para>(1)由block的存储偏移量计算出其所在的Bucket；</para>
							<para>(2)由bucket定位到它所在的bucket分组(bucket分组通过BucketSizeInfo来封装)；</para>
							<para>(3)执行分组对象的freeBlock方法，方法在执行过程中会首先计算该block在Bucket中的存储索引</para>
							<blockquote><para>blockIndex = (block存储偏移量 - bucket存储偏移量) / block大小</para></blockquote>
							<para>然后将该存储索引加入到block所在Bucket的freeList集合中，用于表明该block已经被释放，其他同类型的block可以对其所占用的空间执行覆写操作。</para>
						</listitem>
					</itemizedlist>
				</listitem>
			</orderedlist>
		</section>
		<section>
			<title>使用场景</title>
			<orderedlist>
				<listitem>
					<para>与LruBlockCache搭配使用，缓存所有DATA类型的Block</para>
					<para>在该应用场景下，LruBlockCache默认用来缓存索引块和bloom块(定义表格时可通过声明CACHE_DATA_IN_L1配置来缓存DATA块)，而DATA块全部存储在BucketCache中，如图所示：</para>
					<mediaobject>
						<imageobject>
							<imagedata contentdepth="100%" width="70%" scalefit="1" fileref="../media/hbase/blockcache-1.jpg"></imagedata>
						</imageobject>
					</mediaobject>
					<para>使用该模式需要启用hbase.bucketcache.combinedcache.enabled配置参数(默认为true)，在该模式下，所有的缓存逻辑是通过CombinedBlockCache类来封装的：</para>
					<itemizedlist make='bullet'>
						<listitem>
							<para>缓存写入</para>
							<para>首先判断出要缓存的block类型，如果是DATA块，将数据写入BucketCache，否则将数据写入LruBlockCache。</para>
						</listitem>
						<listitem>
							<para>缓存读取</para>
							<para>首先检索LruBlockCache中的缓存数据，如果要检索的数据不在其中再接着检索BucketCache中的缓存数据。</para>
						</listitem>
						<listitem>
							<para>缓存驱逐操作</para>
							<para>分别执行LruBlockCache和BucketCache中的缓存驱逐逻辑。</para>
						</listitem>
					</itemizedlist>
				</listitem>
				<listitem>
					<para>作为二级缓存使用</para>
					<para>在该模式下，BucketCache负责存储LruBlockCache中淘汰的数据，充当二级缓存功能，具体结构如下图：</para>
					<mediaobject>
						<imageobject>
							<imagedata contentdepth="100%" width="70%" scalefit="1" fileref="../media/hbase/blockcache-2.jpg"></imagedata>
						</imageobject>
					</mediaobject>
					<itemizedlist make='bullet'>
						<listitem>执行缓存操作时，block数据只向LruBlockCache中进行写入，如果其使用空间已满，会驱逐一部分使用不频繁的数据到BucketCache存储中。这样处理后，使用频繁的数据会缓存在LruBlockCache中，相对不频繁的数据保存在BucketCache里。</listitem>
						<listitem>读取缓存中的数据时，同样先检索LruBlockCache，如果没有命中会接着检索BucketCache。</listitem>
					</itemizedlist>
					<tip>该缓存模式并不常用，如果LruBlockCache过大有可能带来内存碎片问题，如若启用该模式还需将hbase.bucketcache.combinedcache.enabled禁用掉(将其属性值设置为false)。</tip>
				</listitem>
			</orderedlist>
		</section>
		<section>
			<title>配置参数</title>
			<para>有关BucketCache的配置参数如下：</para>
			<orderedlist>
				<listitem>
					<para>hbase.bucketcache.size</para>
					<para>指定BucketCache的空间大小(单位：MB)，如果其值小于1，表示占用堆内存的百分比；</para>
				</listitem>
				<listitem>
					<para>hbase.offheapcache.minblocksize</para>
					<para>BucketCache中最小block的大小(默认为64kb)，用于计算BucketCache所能存储block的最大个数；</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.ioengine</para>
					<para>指定BucketCache的存储媒介，堆内存(onheap)、堆外内存(offheap)或者高速磁盘(file)；</para>
					<tip>
						<para>如果使用offheap策略，则jvm参数中MaxDirectMemorySize的大小一定要大于BucketCache的总大小，因为DFSClient也会使用该区域中的内存，具体参考http://hbase.apache.org/book.html#direct.memory</para>
						<para>如果启用file策略，参数值的格式为file:PATH</para>
					</tip>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.combinedcache.enabled</para>
					<para>是否启用CombinedBlockCache(参考BucketCache的使用场景)，默认为true；</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.writer.threads</para>
					<para>写线程数(默认为3)，负责将block数据写入缓存，每个线程有自己的消费队列，队列中存储这将要缓存的block信息；</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.writer.queuelength</para>
					<para>定义每个写线程消费队列的长度(默认为64)；</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.persistent.path</para>
					<para>当采用file作为BucketCache的存储媒介时(通常是高速硬盘，如SSD)，可通过该参数来指定BucketCache元数据的存储路径，这样在集群重启之后可通过读取该路径上的数据将重启前的BucketCache信息迅速还原；</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.percentage.in.combinedcache</para>
					<para>默认参数值为0.9，在启用hbase.bucketcache.combinedcache.enabled参数的情况下，用于计算LruBlockCache和BucketCache的缓存空间，计算公式如下：</para>
					<para>BucketCache大小：hbase.bucketcache.size * hbase.bucketcache.percentage.in.combinedcache</para>
					<para>LRUCache大小(hfile.block.cache.size不再起作用)：hbase.bucketcache.size - BucketCache大小</para>
					<tip>1.0.0版本之后该参数已不在使用，LruBlockCache的大小依然由hfile.block.cache.size参数来决定，详细可参考HBASE-11520。</tip>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.bucket.sizes</para>
					<para>该参数用于指定bucket分组信息，在BucketCache缓存中，所有的buckets是按照不同的size来分组的，不同的分组存储不同大小的block数据，默认值为：5kb,9kb,17kb,33kb,41kb,49kb,57kb,65kb,97kb,129kb,193kb,257kb,385kb,513kb。</para>
				</listitem>
				<listitem>
					<para>hbase.bucketcache.ioengine.errors.tolerated.duration</para>
					<para>缓存容错时间，默认为1分钟。</para>
				</listitem>
			</orderedlist>
		</section>
	</section>
</section>