<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
    xmlns:xlink="http://www.w3.org/1999/xlink"
    xmlns:xi="http://www.w3.org/2001/XInclude"
    xmlns:ns5="http://www.w3.org/2000/svg"
    xmlns:ns4="http://www.w3.org/1998/Math/MathML"
    xmlns:ns3="http://www.w3.org/1999/xhtml"
    xmlns:db="http://docbook.org/ns/docbook">
    <title>计算资源隔离</title>
    <para>计算资源隔离主要是借助于社区的rsgroup特性来实现的(相关jira可参考HBASE-6721)，rsgroup主要实现了对RS的分组管理功能，将具有相似性质的RS聚合到一起形成一个特定的分组，在通过界定不同的分组来实现表级别的粗粒度隔离。</para>
    <mediaobject>
		<imageobject>
			<imagedata contentdepth="100%" width="90%" scalefit="1" fileref="../media/hbase/rsgroup.png"></imagedata>
		</imageobject>
	</mediaobject>
    <para>从逻辑划分上来看，每个RS分组相当于是一个独立的HBase集群。但是与多集群的部署方式相比rsgroup有如下好处：</para>
    <orderedlist>
        <listitem>
            <para>统一了客户端的配置</para>
            <para>客户端的使用不再需要考虑去连接哪个ZK环境。</para>
        </listitem>
        <listitem>
            <para>充分利用主节点的资源</para>
            <para>通常情况下HBase的主节点负荷要远低于从节点，如果集群节点数没有形成规模，主节点的机器资源经常得不到有效利用。而采用rsgroup之后，集群更容易形成一定规模，与多集群的部署方式相比降低了主节点的使用个数。</para>
        </listitem>
        <listitem>
            <para>表格在group之间的迁移相较于在集群之间的迁移变得更加方便和容易。</para>
        </listitem>
        <listitem>
            <para>降低运维成本，只需要维护一个集群即可。</para>
        </listitem>
    </orderedlist>
    <section>
        <title>分组信息维护</title>
        <para>为了便于分组信息的快速访问，HMaster在启动的时候需要将所有的分组信息载入内存以进行预热，而在持久存储层，社区采用的办法是通过独立的hbase:rsgroup表格进行存储，效仿HBase的ACL权限过滤功能，通过zookeeper来协调表格数据与内存数据的一致性。但是，rsgroup信息的访问与acl信息相比有如下本质的不同：acl信息是所有RS都需要预热处理的，因此需要通过ZK来协调他们的一致性，而rsgroup信息只需要在HMaster端进行访问，因此没有必要通过ZK来做中间的协调控制，持久层更新成功以后直接将信息同步至内存即可。持久层也可摒弃hbase:rsgroup表格，而采用其他存储媒介(比如ZK或本地文件)，这样rsgroup的实现复杂度将大大降低，HMaster启动的时候不在需要等待hbase:rsgroup处于online状态。</para>
        <para>分组信息在内存中是通过RSGroupInfoManager类进行管理的，其内部维护了如下两个数据结构：</para>
        <orderedlist>
            <listitem>
                <para>rsGroupMap : Map&lt;String, RSGroupInfo></para>
                <para>用于映射每一个分组名称对应的分组详细信息(组内有哪些Server，部署了哪些表格)。</para>
            </listitem>
            <listitem>
                <para>tableMap : Map&lt;TableName, String></para>
                <para>用于映射每一个表格属于哪一个分组，由数据结构来看，每个表格只能隶属于一个分组。</para>
            </listitem>
        </orderedlist>
        <para>同时提供了如下实用方法用于检索group相关的信息：</para>
        <orderedlist>
            <listitem>
                <para>getRSGroupOfServer</para>
                <para>获取目标Server属于哪个分组。</para>
            </listitem>
            <listitem>
                <para>getRSGroup</para>
                <para>获取指定分组对应的分组明细。</para>
            </listitem>
            <listitem>
                <para>getRSGroupOfTable</para>
                <para>获取目标表格属于哪个分组。</para>
            </listitem>
            <listitem>
                <para>listRSGroups</para>
                <para>返回所有分组明细。</para>
            </listitem>
        </orderedlist>
        <para>为了便于客户端的调用使用，分组信息的维护服务是通过Endpoint方式对外提供的，具体的协处理器实现类为RSGroupAdminEndpoint，在协处理器的内部主要引入了RSGroupAdminService服务，以便通过调用其refresh方法来将分组信息同步至内存，同步过程中需要对持久层的配置做如下校验：</para>
        <orderedlist>
            <listitem>
                <para>同一个Server不能出现在多个group下面。</para>
                <para>否则在对group执行负载均衡操作时有可能会将表格Region迁移到其他group上。</para>
            </listitem>
            <listitem>
                <para>同一个表格不能隶属于多个group。</para>
            </listitem>
            <listitem>
                <para>如果group内部有table部署，则需要确保group下面还有server机器。</para>
            </listitem>
            <listitem>
                <para>确保default分组下面有server机器。</para>
            </listitem>
        </orderedlist>
        <tip><para>与社区处理方式相比有如下不同：社区有关rsgroup的维护办法是先修改内存状态，在同步至持久层；而这里会先修改持久层，再将修改后的状态同步至内存。完整的补丁实现可参考HBASE-18215。</para></tip>
        <para>同时，协处理器还负责RSGroupInfoManager类实例的构造，以便在负载均衡过程中对该类进行调用使用。</para>
    </section>
    <section>
        <title>负载均衡逻辑</title>
        <para>在每个分组内部，Region的负载均衡逻辑是独立于其他分组的，这主要通过RSGroupBasedLoadBalancer来实现(或者通过hbase.rsgroup.grouploadbalancer.class参数来引入自定义的实现类)。从功能上来看，RSGroupBasedLoadBalancer主要实现了负载均衡器的如下几个实用方法(方法通过LoadBalancer接口来声明)：</para>
        <itemizedlist make='bullet'>
            <listitem>
                <para>balanceCluster</para>
                <para>对HMaster执行balance操作时会调用该方法，比如客户端执行balancer命令，方法的执行逻辑大致如下：</para>
                <orderedlist>
                    <listitem>
                        <para>遍历所有已分配的Region，针对每个Region做如下判断处理。</para>
                        <para>首先由Region获取表格信息，再由表格来获取该Region所在的分组(通过调用RSGroupInfoManager类的getRSGroupOfTable方法)，如果当前部署该Region的RS不属于该分组，则将Region移动到BOGUS_SERVER_NAME机器上。</para>
                    </listitem>
                    <listitem>
                        <para>针对BOGUS_SERVER_NAME所部署的Region构造如下类型的RegionPlan。</para>
                        <para>source和dest全部为null，针对该类型的plan，AssignmentManager(简称AM)会执行如下分配处理(代码逻辑参考其balance方法)。</para>
                        <para>(1)首先将plan加入到AM的regionPlans集合。</para>
                        <para>(2)执行AM的unassign方法将目标Region在原有RS上进行下线。</para>
                        <para>(3)下线成功后调用AM的assign方法将目标Region进行重新的分配处理(调用逻辑参考AM的onRegionClosed方法)。分配过程中会去调用balancer的randomAssignment方法来重新生成迁移计划，因为原有计划的dest为null(代码逻辑参考AM的getRegionPlan方法)。</para>
                    </listitem>
                    <listitem>
                        <para>针对分配正常的Region集合进行按组拆分，在针对每一个分组分别调用internalBalancer进行负载均衡处理。</para>
                        <para>internalBalancer为每个分组内部采用的负载均衡实现，可通过hbase.rsgroup.grouploadbalancer.class参数进行指定，默认实现为StochasticLoadBalancer。针对每个分组的负载均衡逻辑目前是采用串行的方式进行处理的，为了加快执行进度可考虑修改成并行。</para>
                    </listitem>
                </orderedlist>
            </listitem>
            <listitem>
                <para>roundRobinAssignment</para>
                <para>当有RS死掉的时候，AssignmentManager会调用该方法来对其上部署的Region进行重新分配，方法的执行逻辑大致如下：</para>
                <orderedlist>
                    <listitem>
                        <para>遍历方法参数所传递过来的所有Region，通过RSGroupInfoManager来获取其隶属的group，从而得到regionMap集合用来映射group和regions。</para>
                    </listitem>
                    <listitem>
                        <para>遍历regionMap集合中的所有group，通过RSGroupInfo来获取group下面有哪些Server，并对offline类型的Server进行过滤，从而得到serverMap集合用来映射group和online状态的RS。</para>
                        <para>如果group下面没有活着的RS，添加BOGUS_SERVER_NAME到group下面，针对该类型的Server，AM会调用processBogusAssignments方法进行处理，将其上部署的Region切换到FAILED_OPEN状态。</para>
                    </listitem>
                    <listitem>
                        <para>遍历regionMap集合，如果group上面有Region部署，调用internalBalancer的roundRobinAssignment对该group进行负载均衡处理。</para>
                        <para>所传递的方法变量可分别从regionMap和serverMap中获取。</para>
                        <tip>在早期的rsgroup实现中存在如下类型的BUG：如果两个group下面都包含BOGUS_SERVER_NAME，执行assignments.putAll操作时将产生覆盖效果，导致部分Region不能切换到FAIL_OPEN状态，详细参考HBASE-18272。</tip>
                    </listitem>
                </orderedlist>
            </listitem>
            <listitem>
                <para>retainAssignment</para>
                <para>对Table执行enable操作时会调用该方法，将Region在其之前部署的RS上重新加载，方法的执行逻辑大致如下：</para>
                <orderedlist>
                    <listitem>
                        <para>遍历方法参数所传递过来的所有Region，进行如下判断处理。</para>
                        <para>如果当前部署该Region的RS并不隶属于目标Region所在的group，将region加入misplacedRegions集合；否则将Region加入groupToRegion集合。</para>
                    </listitem>
                    <listitem>
                        <para>遍历groupToRegion集合，对每一个分组调用internalBalancer的retainAssignment进行处理。</para>
                    </listitem>
                    <listitem>
                        <para>遍历misplacedRegions集合执行如下处理。</para>
                        <para>首先获取目标Region所隶属的group分组，在从分组对象中获取目前处于online状态的Server集合。如果目标分组没有Server处于online状态，将其分配给BOGUS_SERVER_NAME，针对该类型的Server，AM会调用processBogusAssignments方法进行处理。否则调用internalBalancer的randomAssignment方法将目标Region随机分配到其所在group的一台RS上。</para>
                    </listitem>
                </orderedlist>
            </listitem>
            <listitem>
                <para>randomAssignment</para>
                <para>将目标Region随机分配到其所在group的一台RS上。</para>
                <tip>目前社区版本针对该方法的实现并不是很完善，如果随机分配的Server为BOGUS_SERVER_NAME，AM同样会向其发送加载Region的RPC申请。为此可考虑直接返回null，如果返回的结果是BOGUS_SERVER_NAME，这样AM会将目标Region直接切换到FAIL_OPEN状态。</tip>
            </listitem>
        </itemizedlist>
    </section>
    <section>
        <title>功能启用</title>
        <para>启用rsgroup功能只需要对HMaster执行滚动升级即可，需要在hbase-site.xml中添加如下配置项：</para>
        <orderedlist>
            <listitem>
                <para>hbase.master.loadbalancer.class</para>
                <para>将参数值设置为org.apache.hadoop.hbase.rsgroup.RSGroupBasedLoadBalancer。</para>
            </listitem>
            <listitem>
                <para>hbase.coprocessor.master.classes</para>
                <para>通过该配置为HMaster引入org.apache.hadoop.hbase.rsgroup.RSGroupAdminEndpoint协处理器。</para>
            </listitem>
            <listitem>
                <para>hbase.rsgroup.default.groupname</para>
                <para>通过该参数为RS和Table声明默认的group，执行建表操作或扩容操作时，如果没有明确指定group，会将目标RS和Table添加到该group下，默认值为default。</para>
            </listitem>
            <listitem>
                <para>hbase.rsgroup.bulk.balance</para>
                <para>分组之间是否通过并行的方式来构造RegionPlan，默认为串行的方式。</para>
			</listitem>
        </orderedlist>
        <para>同时，hbase通过ruby脚本对外提供了如下常用的运维命令，可通过hbaseshell进行调用使用。</para>
        <orderedlist>
            <listitem>
                <para>get_rsgroup</para>
                <para>获取目标group的分组明细信息，包括：group下面有哪些server节点，以及部署了哪些表格。</para>
            </listitem>
            <listitem>
                <para>get_server_rsgroup</para>
                <para>获取目标server节点属于哪个group分组。</para>
            </listitem>
            <listitem>
                <para>get_table_rsgroup</para>
                <para>获取目标表格部署到了哪个group上面。</para>
            </listitem>
            <listitem>
                <para>list_rsgroups</para>
                <para>获取所有的分组列表(只显示名称)。</para>
            </listitem>
            <listitem>
                <para>balance_rsgroup</para>
                <para>对目标group分组执行单独的balance操作。</para>
            </listitem>
            <listitem>
                <para>move_server_to_group</para>
                <para>将目标Server移动到指定分组下面。注意该方法只是修改了rsgroup的持久层信息，即在ZK上创建/hbase/rsgroup/servers/$server节点，节点的value为目标分组的名称。如果想将这些信息同步至内存还需要执行refresh_group_servers操作。这样处理主要是考虑到move_server_to_group操作一般都是批量进行的，分两阶段处理可降低ZK节点的检索次数。</para>
            </listitem>
            <listitem>
                <para>move_table_to_group</para>
                <para>将目标表格移动到指定分组下面，通过修改ZK的/hbase/rsgroup/tables/$table节点，将节点内容设置成目标分组的名称。不同于move_server_to_group操作，该操作会自动将表格的分组信息同步至内存，而无需在执行refresh_group_servers操作。</para>
            </listitem>
            <listitem>
                <para>refresh_group_servers</para>
                <para>将分组明细信息从ZK同步至内存。</para>
            </listitem>
            <listitem>
                <para>create</para>
                <para>在执行create命令创建表格时，可通过GROUP_NAME元数据信息来声明目标表格将要存放到哪个分组，比如执行如下命令时，会将TestTable表格存放到TEST分组：</para>
                <para>create 'TestTable','cf',{METADATA=>{GROUP_NAME=>'TEST'}}</para>
            </listitem>
        </orderedlist>
    </section>
</section>