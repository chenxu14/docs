<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:ns5="http://www.w3.org/2000/svg"
	xmlns:ns4="http://www.w3.org/1998/Math/MathML"
	xmlns:ns3="http://www.w3.org/1999/xhtml"
	xmlns:db="http://docbook.org/ns/docbook">
	<title>HistoryServer组件</title>
	<para>HistoryServer组件与YARN框架中的JobHistoryServer组件类似，用于查询历史作业信息。组件是从spark1.0版本起开始引入的，启动时作为单独的服务来进行部署，如若启用该功能需添加以下配置信息：</para>
	<orderedlist>
		<listitem>
			<para>spark-default.conf文件中</para>
			<itemizedlist make='bullet'>
				<listitem>
					<para>spark.eventLog.enabled</para>
					<para>将其属性值设置为true，表示开启eventLog功能；</para>
				</listitem>
				<listitem>
					<para>spark.eventLog.dir</para>
					<para>定义eventLog存储路径，可指向hdfs存储，如hdfs://&lt;ns>/tmp/spark-events；</para>
				</listitem>
				<listitem>
					<para>spark.history.updateInterval</para>
					<para>HistoryServer每隔多久检测一次eventLog变动情况，默认为10秒；</para>
				</listitem>
				<listitem>
					<para>spark.history.retainedApplications</para>
					<para>最多存储多少个历史作业，默认为250个；</para>
				</listitem>
				<listitem>
					<para>spark.history.ui.port</para>
					<para>HistoryServer的web访问端口，默认为18080；</para>
				</listitem>
				<listitem>
					<para>spark.history.ui.acls.enable</para>
					<para>是否对组件的访问启用acl校验，acl信息可通过spark.ui.view.acls参数和spark.admin.acls参数来配置。</para>
				</listitem>
				<listitem>
					<para>spark.history.fs.cleaner.enabled</para>
					<para>是否对历史作业启用自动清理功能，默认值为false。</para>
				</listitem>
				<listitem>
					<para>spark.history.fs.cleaner.interval</para>
					<para>自动清理功能开启之后，每隔多久执行一次作业清理(默认每隔1天执行一次)。</para>
				</listitem>
				<listitem>
					<para>spark.history.fs.cleaner.maxAge</para>
					<para>每次清理保留多长时间的历史数据，默认保留7天。</para>
				</listitem>
				<listitem>
					<para>spark.history.fs.logDirectory</para>
					<para>spark作业提交的log目录，historyserver启动后会从该目录加载作业的运行信息。</para>
				</listitem>
				<listitem>
					<para>spark.history.fs.update.interval</para>
					<para>每隔多久检测一次log目录，看是否有新作业生成，如果有将其加载，默认每隔10秒检测一次。</para>
				</listitem>
			</itemizedlist>
		</listitem>
		<listitem>
			<para>spark-env.sh文件中</para>
			<itemizedlist make='bullet'>
				<listitem>
					<para>SPARK_DAEMON_MEMORY</para>
					<para>用于设置启动HistoryServer的堆内存；</para>
				</listitem>
				<listitem>
					<para>SPARK_DAEMON_JAVA_OPTS</para>
					<para>设置JVM运行参数；</para>
				</listitem>
				<listitem>
					<para>SPARK_PUBLIC_DNS</para>
					<para>设置HistoryServer的域名；</para>
				</listitem>
			</itemizedlist>
		</listitem>
	</orderedlist>
	<para>配置项添加成功后可通过如下命令将HistoryServer启动：</para>
	<blockquote><para>./sbin/start-history-server.sh ${spark.eventLog.dir}</para></blockquote>
	<para>如果在spark-default.conf文件中配置了spark.history.fs.logDirectory参数，在执行start-history-server.sh脚本时可不指定脚本的运行参数。HistoryServer组件成功启动后可通过http://&lt;server-url>:18080界面进行访问。</para>
</section>