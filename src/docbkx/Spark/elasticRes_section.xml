<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:ns5="http://www.w3.org/2000/svg"
	xmlns:ns4="http://www.w3.org/1998/Math/MathML"
	xmlns:ns3="http://www.w3.org/1999/xhtml"
	xmlns:db="http://docbook.org/ns/docbook">
	<title>资源弹性申请</title>
	<para>Spark的资源弹性申请功能主要通过ExecutorAllocationManager类来实现，在初始化SparkContext过程中会对该对象进行实例化，对象的内部主要封装了如下变量和数据结构来决定Executor的调度行为：</para>
	<itemizedlist make='bullet'>
		<listitem>
			<para>addTime</para>
			<para>时间戳变量，用来标识资源申请操作将在何时触发，默认为NOT_SET，表示尚不存在Pending状态的任务，无需进行资源申请。</para>
			<para>当作业满足如下运行条件时将会触发资源申请操作：</para>
			<blockquote>
				<para>作业在调度过程中产生了Pending任务(没有可运行的Task槽位)，并且任务的Pending时长已经达到了spark.dynamicAllocation.schedulerBacklogTimeout或spark.dynamicAllocation.sustainedSchedulerBacklogTimeout参数阈值。</para>
			</blockquote>
			<para>这时，将会对addTime进行设置。以便主线程在迭代过程中进行判断，看是否有必要进行资源申请，(代码逻辑可参考updateAndSyncNumExecutorsTarget方法)。</para>
			<para>资源申请过程主要是通过调用addExecutors方法来实现的，大致逻辑如下：</para>
			<orderedlist>
				<listitem>
					<para>首先判断已有资源量是否达到spark.dynamicAllocation.maxExecutors参数阈值</para>
					<para>如果已达峰值将放弃执行资源申请操作。</para>
				</listitem>
				<listitem>
					<para>通过调用ExecutorAllocationClient类的requestTotalExecutors方法来进行资源申请</para>
					<para>方法执行后会向YarnSchedulerEndpoint发送RequestExecutors消息(通过AKKA)，YarnSchedulerEndpoint收到消息后将其转发给AMEndpoint，AMEndpoint端会通过YarnAllocator来构造ResourceRequest申请，并将其发送到ResourceManager端，然后通过不断心跳来完成异步申请逻辑。</para>
					<tip>每次动态申请的Executor数量呈指数级增长，e.g.第一次申请1个，下次将申请2个，接下来是4个，8个...</tip>
				</listitem>
			</orderedlist>
		</listitem>
		<listitem>
			<para>removeTimes</para>
			<para>数据结构为Map&lt;executorId, timestamp>，用来标识目标Executor将在何时被回收。</para>
			<para>当作业满足如下运行条件时将会触发资源回收操作：</para>
			<blockquote>
				<para>目标Executor在一段时间内没有部署任何Task，其空闲时长达到spark.dynamicAllocation.executorIdleTimeout参数阈值。</para>
			</blockquote>
			<para>这时，Executor将被加入removeTimes集合，以便主线程在迭代过程中进行判断，看是否可以对该Executor进行回收(代码逻辑参考schedule方法)。资源释放过程主要是通过调用removeExecutor方法来实现的，方法在执行过程中会调用ExecutorAllocationClient类的killExecutor方法来将目标Executor杀死。</para>
		</listitem>
	</itemizedlist>
	<para>ExecutorAllocationManager在实例化过程中会注册ExecutorAllocationListener监听对象来监听调度器的相关行为，当有以下事件触发时会进行相应的回调处理。</para>
	<itemizedlist make='bullet'>
		<listitem>
			<para>onStageSubmitted，当有Stage提交时触发</para>
			<para>Stage提交以后，其内部所包含的任务尚处于Pending状态，此时需要对addTime进行设置，用来表示如果一段时间之后，任务依然Pending，将开始申请新的Executor资源。</para>
		</listitem>
		<listitem>
			<para>onStageCompleted，当有Stage运行结束时触发</para>
			<para>如果Stage运行结束后，作业中不再有Pending任务，将addTime重置成NOT_SET，表示不再需要申请Executor资源。</para>
		</listitem>
		<listitem>
			<para>onTaskStart，当有Task启动时触发</para>
			<para>首先判断目标作业是否还有其他Pending任务，如果没有将addTime重置成NOT_SET。然后将目标Task所在的Executor标记为busy状态(将其从removeTimes集合中移除，来防止其被回收)。</para>
		</listitem>
		<listitem>
			<para>onTaskEnd，当有Task运行结束时触发</para>
			<para>如果Task所在的Executor已经没有其他Task在运行了，将该Executor标记成idle状态(加入removeTimes集合，空闲一段时间后将会被回收).而如果Task是运行失败的任务(比如其所在的Executor被kill了)，并且当前作业已经没有其他任务处于Pending状态了(这时addTime变量值将会是NOT_SET)，此时需要确保作业中有足够的Executor来对失败的Task进行重新部署，解决办法是设置addTime，使其变量值不为NOT_SET，这样即使作业没有资源也会进行新的申请(详细参考SPARK-8366)。</para>
		</listitem>
	</itemizedlist>
	<section>
		<title>相关配置</title>
		<itemizedlist make='bullet'>
			<listitem>
				<para>spark.dynamicAllocation.enabled</para>
				<para>是否启用动态资源申请功能，默认值为false。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.minExecutors</para>
				<para>作业最少资源(Executor数量)保证量，默认值为0。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.maxExecutors</para>
				<para>作业最大资源保证量，默认不限制。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.schedulerBacklogTimeout</para>
				<para>如果作业在调度过程中产生了pending任务，并且pending时长达到该参数阀值(默认为1秒)，开始申请新的Executor。</para>
				<para>每次申请的Executor数呈倍数增长，比如第一次申请了2个Executor，在下次申请时将会申请4个。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.sustainedSchedulerBacklogTimeout</para>
				<para>功能与schedulerBacklogTimeout类似，只不过用于限制第一次申请之后的时间阈值，默认值为1秒。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.executorIdleTimeout</para>
				<para>executor空闲时间超过该阀值，将其资源进行回收，默认时间60秒。</para>
			</listitem>
			<listitem>
				<para>spark.dynamicAllocation.cachedExecutorIdleTimeout</para>
				<para>如果目标Executor含有缓存数据(cached blocks)，空闲时间超过该阀值，将其回收。默认情况下不进行回收，如果其含有RDD缓存数据。在以后的版本中，可能会将RDD缓存放到NodeManager层面来管理(通过堆外内存)</para>
			</listitem>
		</itemizedlist>
	</section>
	<section>
		<title>功能启用</title>
		<orderedlist>
			<listitem>
				<para>首先将spark-&lt;version>-yarn-shuffle.jar拷贝到每个NM节点的$HADOOP_HOME/share/hadoop/yarn目录下</para>
			</listitem>
			<listitem>
				<para>修改yarn-site.xml，添加如下配置项：</para>
				<para>yarn.nodemanager.aux-services，引入spark_shuffle服务</para>
				<para>yarn.nodemanager.aux-services.spark_shuffle.class，参数值设置为org.apache.spark.network.yarn.YarnShuffleService</para>
			</listitem>
			<listitem>
				<para>最后在spark端开启spark.dynamicAllocation.enabled配置以及spark.shuffle.service.enabled配置，将其属性值设成true。</para>
			</listitem>
		</orderedlist>
	</section>
</section>