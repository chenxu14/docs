<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
	xmlns:xlink="http://www.w3.org/1999/xlink"
	xmlns:xi="http://www.w3.org/2001/XInclude"
	xmlns:ns5="http://www.w3.org/2000/svg"
	xmlns:ns4="http://www.w3.org/1998/Math/MathML"
	xmlns:ns3="http://www.w3.org/1999/xhtml"
	xmlns:db="http://docbook.org/ns/docbook">
	<title>CapacityScheduler计算能力调度器</title>
	<para>在不修改配置的情况下，Yarn框架默认使用该调度器，该调度器实现了多租户共享集群资源的调度逻辑，租户之间按需使用计算资源，使得资源的使用具有弹性，提高使用率。同时给与每个租户最低的计算能力保障，在最低保障之上可以使用系统的空闲资源以此来实现弹性和可伸缩性。</para>
	<para>CapacityScheduler按照队列的计算能力来分配资源比例，这样可以保证比较重要的任务能够优先获取更多的资源，比如两个队列A和B，A的计算能力为30，B的计算能力为70，将比较重要的任务放到B队列中即可。</para>
	<para>调度器的特性如下：</para>
	<blockquote>
		<para>1.计算能力保障 – 提供了很多队列，计算能力按队列划分，任务提交到队列中；</para>
		<para>2.安全 - 每个队列都拥有acl访问控制列表来控制哪些用户可提交任务到队列；</para>
		<para>3.弹性 – 当队列的计算资源不够用时，可以使用其他队列空闲的资源；</para>
		<para>4.多租户 - 多租户共享集群；</para>
		<para>5.可操作性 – 队列的定义和相关属性的修改是可配置的，并且可在运行时修改；</para>
		<para>6.基于资源的调度 - 资源包括内存和vcpu；</para>
	</blockquote>
	<section>
		<title>调度器配置参数</title>
		<orderedlist>
			<listitem>
				<para>yarn.scheduler.capacity.root.queues</para>
				<para>指定根队列有哪些子队列(子队列名字用逗号分隔)</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.capacity</para>
				<para>分配给&lt;queue-path>队列的计算资源所占总资源的百分比，所有队列的计算资源加在一起应小于等于100</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.maximum-capacity</para>
				<para>当队列的资源使用率达到上限时，可通过配置该属性让该队列使用其他队列的空闲资源，数值为最大使用资源所占总资源的百分比，默认为-1表示可以使用全部资源</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.minimum-user-limit-percent</para>
				<para>多个用户同时向该队列提交job，每个用户所分配的资源的最小百分比(eg:假设该值为25，如果有两个用户使用该队列，则每个用户可占有队列50%的资源；如果有3个用户使用该队列则每个用户可占有队列33%的资源，而如果有4个或以上的用户使用该队列，则每个用户占有队列25%的资源)</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.user-limit-factor</para>
				<para>默认为1，表示用户所使用的资源不能超过&lt;queue-name>队列的容量</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.maximum-applications</para>
				<para>系统可并发的最大job数(默认为10000)，并发job按照每个队列的计算能力来分配(eg,假设queue1的capacity为10，而系统允许最多20个并发任务，则queue1允许并发2个job)</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.maximum-applications</para>
				<para>覆盖6中的配置，硬性指定每个队列可处理的最大job数</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.maximum-am-resource-percent</para>
				<para>AM使用资源所占系统总资源的最大百分比，该配置是针对所有队列的一个全局配置，个别队列如果想修改该百分比可通过配置9来完成。</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.maximum-am-resource-percent</para>
				<para>覆盖8中的配置，为指定队列硬性指定AM的使用资源所占系统总资源的百分比</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.&lt;queue-path>.state</para>
				<para>为指定队列设置状态(RUNNING或者STOPPED)，如果设置成STOPPED状态，队列不再接收新job</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.root.&lt;queue-path>.acl_submit_applications</para>
				<para>指定哪些用户可向&lt;queue-path>提交job</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.capacity.root.&lt;queue-path>.acl_administer_queue</para>
				<para>指定哪些用户可管理&lt;queue-path>中的job</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.minimum-allocation-mb</para>
				<para>每个Container最小分配内存</para>
			</listitem>
			<listitem>
				<para>yarn.scheduler.maximum-allocation-mb</para>
				<para>每个Container最大分配内存</para>
			</listitem>
		</orderedlist>
	</section>
	<section>
		<title>调度器工作流程</title>
		<orderedlist>
			<listitem>
				<para>当APP_ADDED事件触发时，提交作业到指定队列</para>
				<para>作业的提交通过CSQueue的submitApplication方法来实现，方法在执行过程中首先进行以下判断：</para>
				<blockquote>
					<para>(1)当前用户是否有权限操作该队列(配置11和配置12)</para>
					<para>(2)队列是否处于RUNNING状态(配置10)</para>
					<para>(3)该队列所能承载的job数是否达到上限(配置7)</para>
					<para>(4)用户所提交的job数是否超越队列分配给他的上限值，计算方法：</para>
					<para>maxAppsPerUser=(maxApps*(userLimit/100.0f)*userLimitFactor)</para>
					<tip>其中maxApps通过配置7指定，userLimit通过配置4指定，userLimitFactor通过配置5指定。</tip>
				</blockquote>
				<para>所有校验通过之后执行LeafQueue的activeApplications方法，对已提交的job进行激活。</para>
			</listitem>
			<listitem>
				<para>作业激活</para>
				<para>激活操作首先将用户提交的job放入activeApplications集合中，激活之前进行以下判断：</para>
				<blockquote>
					<para>(1)已激活的job数量是否超过系统能够承受的上限值，上限计算方法：</para>
					<para>maxActiveApps=(clusterRes/minAllocation)*absMaxCapacity*maxAMResPercent</para>
					<tip>其中clusterRes为集群内存资源的总和，minAllocation通过配置13来指定，absMaxCapacity通过配置3来计算，maxAMResPercent通过配置9来指定。</tip>
					<para>(2)当前用户激活的job数量是否超过队列分配给他的上限值，上限计算方法：</para>
					<para>maxActiveAppsPerUser=maxActiveApps*(userLimit/100.0f)*userLimitFactor</para>
					<tip>其中，maxActiveApps计算方法与上一步类似，只是将absMaxCapacity(配置3)换成了absCapacity(配置2)；其他参数userLimit通过配置4来指定，userLimitFactor通过配置5来指定。</tip>
				</blockquote>
				<para>如果激活失败，则将job放入等待队列(pendingApplications)。</para>
			</listitem>
			<listitem>
				<para>构造ResourceRequest，用于申请Container</para>
				<para>Job成功激活后调度器会触发RMAppAttemptEventType.APP_ACCEPTED事件，使AppAttempt状态机进行相应处理，处理过程中主要使用了CapacityScheduler的allocate方法向当前FiCaSchedulerApp中注册ResourceRequest用于申请运行AM的Container(在CapacityScheduler视图中，作业是通过FiCaSchedulerApp来封装的)。</para>
				<para>至此，APP_ADDED事件处理结束，最终结果是构造了用于申请AM Container的ResourceRequest，然而申请何时被响应？主要是通过NODE_UPDATE事件。</para>
			</listitem>
			<listitem>
				<para>响应ResourceRequest请求，处理Container分配</para>
				<para>首先分配处于reserve状态下的Container。</para>
				<tip>Container对象构建成功后，由于Node资源不足，会将该Container标记为reserve状态，直到节点有做够的资源时在做分配处理。</tip>
				<para>如果不存在reserve状态的Container，执行CSQueue.assignContainers方法为所有队列中已激活的作业分配Container，Container在分配过程中采用的是三级资源分配策略，步骤如下：</para>
				<para>(1)首先，基于深度优先、资源使用率越低越优先的原则遍历所有队列；</para>
				<para>(2)然后，遍历队列中所有处于激活状态的作业(基于fifo原则)</para>
				<blockquote>
					<para>如果Node在当前作业的调度黑名单里，则跳过该作业到下一条，否则遍历注册到该作业中的ResourceRequests，做如下校验处理：</para>
					<para>如果请求的资源+队列已使用的资源>队列可提供的资源上限，返回NULL_ASSIGNMENT，表示该队列暂时无法分配资源；</para>
					<para>如果该作业的提交用户已申请的资源 > 队列分配给他的资源上限，则终止对该作业的资源分配，继续下一条作业。</para>
				</blockquote>
				<para>(3)如果步骤2中的校验通过，开始执行LeafQueue.assignContainersOnNode方法来完成Container的分配处理，方法逻辑如下。</para>
				<para>首先，根据ResourceRequest的name属性来决定Container的分配行为；</para>
				<blockquote>
					<para>如果name信息与Node名字相同，则以NODE_LOCAL的方式分配Container(优先处理)</para>
					<para>如果name信息与Node所在机柜名字相同，则以RACK_LCOAL的方式分配Container(次优先)</para>
					<para>如果name信息为*，则以OFF_SWITCH的方式分配Container(最后处理)</para>
				</blockquote>
				<para>其次，如果要申请的Container资源已经超过了Node所能够提供的资源上限，则返回Resource.none()来表示并未进行分配处理；</para>
				<para>接着，在Node还有可用空闲资源的情况下，构造Container对象；</para>
				<tip>
					<para>Container作为YARN框架的分布式运行单元，主要充当AM、MapTask和ReduceTask的运行容器，其内部封装以下基本信息：</para>
					<para>ContainerId：Contaianer的全局ID</para>
					<para>NodeId：Container部署在哪个Node上</para>
					<para>Resource：分配到该Container的资源大小，包括内存、vcpu数</para>
					<para>Priority：优先级</para>
					<para>token：访问令牌</para>
					<para>httpAddress：所在Node的http url</para>
				</tip>
				<para>最后，判断该Node是否还有足够的资源来部署该Container。</para>
				<blockquote>
					<para>如果没有，将Container标识为Reserved状态，等下次心跳通信时在尝试部署；</para>
					<para>如果有，触发RMContainerEventType.START事件，使RMContainer状态机做相应处理，由RMContainer的状态转移表可以看到事件触发后，RMContainer状态机主要执行了ContainerStartTransition这个钩子函数，钩子函数的作用是触发RMAppAttemptEventType.CONTAINER_ALLOCATED事件使AppAttempt状态机进入Allocated_Saving状态，同时将新创建的Container对象和AppAttempt对象进行绑定，以此来完成对Container的分配处理。</para>
				</blockquote>
			</listitem>
		</orderedlist>
	</section>
</section>